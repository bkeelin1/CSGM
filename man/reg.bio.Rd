% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/reg.bio.R
\name{reg.bio}
\alias{reg.bio}
\title{reg.bio - A Robust Multiple, Multivariate Regression Algorithm}
\usage{
reg.bio(
  Response,
  Predictor,
  type = "pred",
  p_calc = "gcv",
  n_boot = 25,
  perm = 500,
  CV = TRUE,
  which_classify = NULL,
  full_model = TRUE,
  VIPS = NULL,
  parallel = TRUE,
  core_choice = "detect",
  print_progress = TRUE,
  ...
)
}
\arguments{
\item{Response}{A matrix or data frame containing the response variables to be predicted}

\item{Predictor}{A matrix or data frame containing the predictor variables}

\item{type}{Character; type of analysis to perform: "pred" for prediction or "class" for classification}

\item{p_calc}{Character; method for p-value calculation ("RMSE", "R2", "F", "gcv", or "coef")}

\item{n_boot}{Integer; number of bootstrap iterations (default: 0)}

\item{perm}{Integer; number of permutations for significance testing (default: 500)}

\item{CV}{Logical; whether to perform cross-validation (default: TRUE)}

\item{which_classify}{Vector; optional indices for specific observations to classify}

\item{full_model}{Logical value indicating whether to use full model without variable trimming. Default is FALSE to perform test using trimmed model rather than using colinear and/or uninformative variables.}

\item{VIPS}{Vector; optional variable importance scores}

\item{parallel}{Logical value whether to use parallel processing (default: TRUE)}

\item{core_choice}{Character value specifying number of cores to use.
The following options are available:
\itemize{
\item{"detect"} {:  total available cores - 2}
\item{"high"} {:  28 cores}
\item{"medium-high"} {:   20 cores}
\item{"medium"} {:  14 cores}
\item{"medium-low"} {:  10 cores}
\item{"low"} {:   8 cores}
} ("detect" , "high", "medium-high", "medium", "medium-low", "low", or specific number)}

\item{print_progress}{Logical value whether to display progress bars (default: TRUE)}

\item{...}{Additional arguments passed for \code{DT}, \pkg{caret}, and \pkg{e1071} parameters}

\item{package}{Character; specifies the package to use: "svm" (e1071) or "caret"}
}
\value{
A list of class "pred" containing:
\itemize{
\item Model:         Formula representation of the fitted model
\item Coefficients:  Matrix of model coefficients
\item Prediction:    Matrix or array of predicted values
\item summary (when type == "pred") - Data frame containing model statistics including:
\itemize{
\item n_perm:      Number of permutations used
\item n_boot:      Number of bootstrap iterations
\item df:          Degrees of freedom
\item F_stat:      F-statistic
\item RMSE:        Root mean square error
\item R2:          R-squared value
\item BIC_test:    Bayesian Information Criterion
\item p_value:     Statistical significance of the model.
}
\item summary (when type == "class") - Data frame containing model statistics including:
\itemize{
\item n_perm:                Number of permutations used.
\item n_boot:                Number of bootstrap iterations.
\item df:                    Degrees of freedom.
\item Sensitivity:           Proportion of actual positives correctly identified (True Positive Rate).
\item Specificity:           Proportion of actual negatives correctly identified (True Negative Rate).
\item Pos Pred Value:        Proportion of predicted positives that are actual positives.
\item Neg Pred Value:        Proportion of predicted negatives that are actual negatives.
\item Precision:             How precise the positive predictions are.
\item Recall:                Ability of the model to identify positive cases.
\item F1:                    Harmonic mean of Precision and Recall
\item Prevalence:            Proportion of positive cases in the dataset.
\item Detection Rate:        Proportion of true positives out of the total observations.
\item Detection Prevalence:  Proportion of predicted positive cases out of the total observations.
\item Balanced Accuracy:     Mean of Sensitivity and Specificity, useful for imbalanced datasets.
\item p_value: Indicates     Statistical significance of the model.
}
}
}
\description{
The reg.bio function is a comprehensive regression tool designed for conducting complex
multivariate regression analyses in cross-sectioanl geometric morphometric
applications. It incorporates traditional regression approaches and modern machine learning methods
by implementing both classification and prediction capabilities within a unified
framework. The function particularly excels at handling high-dimensional data common
in morphometric studies, offering robust solutions for both linear and non-linear
relationships between variables.

At its core, the function utilizes support vector machines (SVM) through either the
caret or e1071 packages, enhanced with permutation testing capabilities to provide
statistical rigor in morphometric analyses. It automatically handles data
preprocessing, model validation, and statistical testing, making it particularly
suitable for analyzing shape variation and morphological data. The function can
process both single and multiple response variables, making it versatile for various
research scenarios in geometric morphometrics.

The function conducts model validation techniques through
cross-validation and bootstrapping, along with permutation testing for statistical
significance. These features ensure robust results even with the complex,
multivariate data structures common in morphometric analyses. The function also
provides comprehensive model diagnostics and performance metrics, crucial for
understanding the reliability and accuracy of morphometric predictions.
}
\details{
The reg.bio function operates through a sophisticated multi-step process that ensures
robust analysis of morphometric data. Initially, it performs extensive data validation
and preprocessing, including automatic handling of factor levels and data type
conversions. The function supports both prediction and classification tasks,
automatically adjusting its internal algorithms based on the nature of the response
variables.

For model fitting, the function employs a flexible approach that can utilize either
the caret or e1071 package's implementation of support vector machines. When using
caret, it takes advantage of the package's extensive model tuning capabilities,
automatically optimizing model parameters through cross-validation. With e1071, it
implements direct SVM fitting with customizable kernel functions and parameter settings.

The validation process integrates several critical components. When cross-validation
is enabled, the function implements a k-fold validation scheme, systematically
evaluating model performance across different data partitions. The bootstrapping
option provides an additional layer of validation, generating confidence intervals
for model parameters and predictions. These validation procedures are particularly
important in morphometric analyses where understanding the stability and reliability
of shape predictions is crucial.

Statistical significance is assessed through a sophisticated permutation testing
framework. The function generates null distributions by randomly permuting the
response variables while maintaining the correlation structure of the predictors.
This approach provides robust p-values that account for the multivariate nature of
morphometric data. The permutation process includes an adaptive convergence check,
potentially reducing computational time while maintaining statistical rigor.

The function implements parallel processing capabilities to handle computationally
intensive tasks efficiently. It automatically manages parallel processes based on
the specified core choice, with built-in options for different levels of parallel
processing intensity. This feature is particularly valuable when working with large
morphometric datasets or when performing extensive permutation testing.

Variable importance analysis is integrated into the function, allowing researchers
to identify which morphometric variables contribute most significantly to the
observed patterns. This analysis can be performed through various methods, including
coefficient analysis and dedicated variable importance calculations, depending on
the chosen modeling approach.

The function also handles PCA transformations for response
variables, which is particularly useful in geometric morphometric analyses where
dimensional reduction is often necessary. It automatically manages the transformation
and back-transformation of data, ensuring that results are presented in the original
coordinate space while taking advantage of the statistical benefits of PCA.

Error handling and input validation are comprehensive throughout the function, with
informative messages and warnings to guide users in correctly specifying analyses.
The function also implements memory management strategies to handle large datasets
efficiently, including cleanup of intermediate results and optimal storage of model
components.
}
\examples{
\dontrun{
# Basic usage for prediction
result <- pred(Response = y_data,
              Predictor = x_data,
              type = "pred")

# Classification with cross-validation
class_result <- pred(Response = class_data,
                    Predictor = predictors,
                    type = "class",
                    CV = TRUE,
                    n_boot = 100)

# Parallel processing with custom cores
parallel_result <- pred(Response = y_data,
                       Predictor = x_data,
                       parallel = TRUE,
                       core_choice = "medium-high")
}

}
\seealso{
\code{\link[caret]{train}} for the underlying caret implementation
\code{\link[e1071]{svm}} for the underlying SVM implementation
}
\author{
Keeling et al., 2025
}
